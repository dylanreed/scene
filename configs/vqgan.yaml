model:
  in_channels: 3
  hidden_channels: 128
  num_res_blocks: 2
  codebook_size: 512
  codebook_dim: 256
  # 320x200 -> 20x12 tokens (16x downscale)
  downsample_factor: 16

training:
  batch_size: 16        # 16GB allows larger batches = fewer steps = faster
  learning_rate: 0.00015  # slightly higher with larger batch
  num_epochs: 100
  save_every: 1
  sample_every: 1

data:
  # Height must be divisible by 16 (downsample_factor)
  # 200 -> 192 (closest divisible by 16)
  image_size: [320, 192]
  data_dir: "data/images"
